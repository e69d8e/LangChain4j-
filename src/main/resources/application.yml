server:
  port: 8080
#langchain4j测试模型
#langchain4j:
#  open-ai:
#    chat-model:
#      api-key: demo
#      model-name: gpt-4o-mini
#      temperature: 0.7
#      base-url: http://langchain4j.dev/demo/openai/v1
#      #请求和响应日志
#      log-requests: true
#      log-responses: true
#启用日志debug级别
logging:
  level:
    root: info
langchain4j:
  open-ai:
    ## deep_seek
#    chat-model:
#      base-url: https://api.deepseek.com
#      api-key: ${DEEP_SEEK_API_KEY}
#      model-name: deepseek-chat
#      temperature: 0.7
#      #请求和响应日志
#      log-requests: true
#      log-responses: true
      chat-model:
        base-url: https://dashscope.aliyuncs.com/compatible-mode/v1
        api-key: ${DASH_SCOPE_API_KEY}
        model-name: deepseek-r1
        temperature: 0.7
        #请求和响应日志
        log-requests: true
        log-responses: true

  # ollama
  ollama:
    chat-model:
      base-url: http://localhost:11434
      model-name: qwen2.5:3b
      temperature: 0.7
      #请求和响应日志
      log-requests: true
      log-responses: true
  ## dash_scope_qwen
  community:
    dashscope:
      chat-model:
        api-key: ${DASH_SCOPE_API_KEY}
        model-name: qwen-plus
        parameters:
          temperature: 0.7
  ## dash_scope_deepseek
#  community:
#    dashscope:
#      chat-model:
#        api-key: ${DASH_SCOPE_API_KEY}
#        model-name: deepseek-r1
#        parameters:
#          temperature: 0.7
spring:
  data:
    mongodb:
      uri: mongodb://localhost:27017/chat_memory_db